analysis:
  analyzer:
    term_index:
      tokenizer: edge_ngram_2
      filter:
      - lowercase
      - asciifolding
      char_filter:
      - hyphen
      - phonetic_mappings
    term_search:
      tokenizer: keyword
      filter:
      - asciifolding
      - lowercase
      char_filter:
      - hyphen
      - phonetic_mappings
  tokenizer:
    edge_ngram_2:
      type: edgeNGram
      min_gram: 2
      max_gram: 50
      token_chars:
      - letter
      - digit
      - whitespace
  char_filter:
    hyphen:
      type: pattern_replace
      pattern: "[-]"
      replacement: ''
    phonetic_mappings:
      type: mapping
      mappings:
      - "รป => y"
      - "ph => f"
      - "w => v"
